# -*- coding: utf-8 -*-
"""Copy of main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1doqRGk8AuOGGtxeB3JpdnnCtYxPoleF0
"""

# mount drive for data files
from google.colab import drive
drive.mount('/content/drive')

# imports
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import ast
import subprocess
import sentence_transformers
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# get data
df_taxonomy = pd.read_csv('/content/drive/MyDrive/bia_has_growing_up_to_do_2025_september/veridion_deeptech_engineer/insurance_taxonomy.csv')
df_companies = pd.read_csv('/content/drive/MyDrive/bia_has_growing_up_to_do_2025_september/veridion_deeptech_engineer/ml_insurance_challenge.csv')

# initial data overview
print('\n---- Company data overview ----')
print('---- shape: ' + str(df_companies.shape))
print('---- columns: ' + str(df_companies.columns.tolist()))
print(df_companies.info())
print('---- missing values:\n' + str(df_companies.isnull().sum().to_string()))
print('---- duplicates: ' + str(df_companies.duplicated().sum()))
print('---- unique values:\n' + str(df_companies.nunique().to_string()))
print('---- head: ' + str(df_companies.head().to_string()))

print('\n\n---- Taxonomy data overview ----')
print('---- shape: ' + str(df_taxonomy.shape))
print('---- columns: ' + str(df_taxonomy.columns.tolist()))
print(df_taxonomy.info())
print('---- missing values:\n' + str(df_taxonomy.isnull().sum().to_string()))
print('---- duplicates: ' + str(df_taxonomy.duplicated().sum()))
print('---- unique values:\n' + str(df_taxonomy.nunique().to_string()))
print('---- head: ' + str(df_taxonomy.head().to_string()))

# plot companies by sector
plt.figure(figsize=(10, 6))
sns.countplot(y='sector', data=df_companies, order=df_companies['sector'].value_counts().index)
plt.title('Distribution of companies by sector')
plt.xlabel('No. companies')
plt.ylabel('Sector')
plt.tight_layout()
plt.savefig('sector_distribution.png')

# replace missing values with empty strings
for col in df_companies.columns.tolist():
    df_companies[col].fillna('', inplace=True)

# drop duplicates
df_companies.drop_duplicates(inplace=True)

print('---- Company data overview check ----')
print('---- missing values:\n' + str(df_companies.isnull().sum().to_string()))
print('---- duplicates: ' + str(df_companies.duplicated().sum()))

# unified 'full_text' column for classification
def parse_tags(tags_str):
    try:
        tags = ast.literal_eval(tags_str)
        return [str(tag).strip() for tag in tags] if isinstance(tags, list) else []
    except (ValueError, SyntaxError):
        return []

df_companies['tags_list'] = df_companies['business_tags'].apply(parse_tags)
df_companies['full_text'] = df_companies.apply(
    lambda row: f"{row['description']} {' '.join(row['tags_list'])} {row['niche']}",
    axis=1
)

# classifier building using a pre-trained sentence-transformer model
# 'all-MiniLM-L6-v2' is a great model that provides a good balance of speed and performance
model = SentenceTransformer('all-MiniLM-L6-v2')

# embeddings gen
company_embeddings = model.encode(df_companies['full_text'].tolist(), show_progress_bar=True)
label_embeddings = model.encode(df_taxonomy['label'].tolist(), show_progress_bar=True)

# company classification
# cosine similarity between each company embedding and all label embeddings
similarity_matrix = cosine_similarity(company_embeddings, label_embeddings)

# label index with the highest similarity score
best_match_indices = np.argmax(similarity_matrix, axis=1)

# label name retrieving basedd on index
predicted_labels = df_taxonomy_['label'].iloc[best_match_indices].values
similarity_scores = np.max(similarity_matrix, axis=1)

# add results
df_companies['insurance_label'] = predicted_labels
df_companies['similarity_score'] = similarity_scores
df_companies.to_csv('classified_companies.csv', index=False)
df_companies.to_csv('/content/drive/MyDrive/bia_has_growing_up_to_do_2025_september/veridion_deeptech_engineer/classified_companies.csv', index=False)

print("\n--- Sample of Classified Companies ---")
pd.set_option('display.max_colwidth', 200)
print(df_companies[['description', 'insurance_label', 'similarity_score']].head())